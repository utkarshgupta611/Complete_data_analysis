{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your Client FinMan is a financial services company that provides various financial services like loan, investment funds, insurance etc. to its customers. FinMan wishes to cross-sell health insurance to the existing customers who may or may not hold insurance policies with the company. The company recommend health insurance to it's customers based on their profile once these customers land on the website. Customers might browse the recommended health insurance policy and consequently fill up a form to apply. When these customers fill-up the form, their Response towards the policy is considered positive and they are classified as a lead.\n",
    "\n",
    "Once these leads are acquired, the sales advisors approach them to convert and thus the company can sell proposed health insurance to these leads in a more efficient manner.\n",
    "\n",
    "Now the company needs your help in building a model to predict whether the person will be interested in their proposed Health plan/policy given the information about:\n",
    "\n",
    "- Demographics (city, age, region etc.)\n",
    "- Information regarding holding policies of the customer\n",
    "- Recommended Policy Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 1: Importing the Relevant Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic eda library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Pre-Processing Library \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Imputer \n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Model Tunning \n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "# ML Model\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Metrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# To hide or filtering Warning for clear view\n",
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Customising Visulization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc = {'figure.figsize':(16,5)})\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_Df64byy.csv')\n",
    "test_df = pd.read_csv('test_YCcRUnU.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>City_Code</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Accomodation_Type</th>\n",
       "      <th>Reco_Insurance_Type</th>\n",
       "      <th>Upper_Age</th>\n",
       "      <th>Lower_Age</th>\n",
       "      <th>Is_Spouse</th>\n",
       "      <th>Health Indicator</th>\n",
       "      <th>Holding_Policy_Duration</th>\n",
       "      <th>Holding_Policy_Type</th>\n",
       "      <th>Reco_Policy_Cat</th>\n",
       "      <th>Reco_Policy_Premium</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>C3</td>\n",
       "      <td>3213</td>\n",
       "      <td>Rented</td>\n",
       "      <td>Individual</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>No</td>\n",
       "      <td>X1</td>\n",
       "      <td>14+</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22</td>\n",
       "      <td>11628.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>C5</td>\n",
       "      <td>1117</td>\n",
       "      <td>Owned</td>\n",
       "      <td>Joint</td>\n",
       "      <td>75</td>\n",
       "      <td>22</td>\n",
       "      <td>No</td>\n",
       "      <td>X2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "      <td>30510.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>C5</td>\n",
       "      <td>3732</td>\n",
       "      <td>Owned</td>\n",
       "      <td>Individual</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19</td>\n",
       "      <td>7450.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>C24</td>\n",
       "      <td>4378</td>\n",
       "      <td>Owned</td>\n",
       "      <td>Joint</td>\n",
       "      <td>52</td>\n",
       "      <td>48</td>\n",
       "      <td>No</td>\n",
       "      <td>X1</td>\n",
       "      <td>14+</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19</td>\n",
       "      <td>17780.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>C8</td>\n",
       "      <td>2190</td>\n",
       "      <td>Rented</td>\n",
       "      <td>Individual</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>No</td>\n",
       "      <td>X2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>10404.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID City_Code  Region_Code Accomodation_Type Reco_Insurance_Type  Upper_Age  \\\n",
       "0   1        C3         3213            Rented          Individual         36   \n",
       "1   2        C5         1117             Owned               Joint         75   \n",
       "2   3        C5         3732             Owned          Individual         32   \n",
       "3   4       C24         4378             Owned               Joint         52   \n",
       "4   5        C8         2190            Rented          Individual         44   \n",
       "\n",
       "   Lower_Age Is_Spouse Health Indicator Holding_Policy_Duration  \\\n",
       "0         36        No               X1                     14+   \n",
       "1         22        No               X2                     NaN   \n",
       "2         32        No              NaN                     1.0   \n",
       "3         48        No               X1                     14+   \n",
       "4         44        No               X2                     3.0   \n",
       "\n",
       "   Holding_Policy_Type  Reco_Policy_Cat  Reco_Policy_Premium  Response  \n",
       "0                  3.0               22              11628.0         0  \n",
       "1                  NaN               22              30510.0         0  \n",
       "2                  1.0               19               7450.0         1  \n",
       "3                  3.0               19              17780.0         0  \n",
       "4                  1.0               16              10404.0         0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>City_Code</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Accomodation_Type</th>\n",
       "      <th>Reco_Insurance_Type</th>\n",
       "      <th>Upper_Age</th>\n",
       "      <th>Lower_Age</th>\n",
       "      <th>Is_Spouse</th>\n",
       "      <th>Health Indicator</th>\n",
       "      <th>Holding_Policy_Duration</th>\n",
       "      <th>Holding_Policy_Type</th>\n",
       "      <th>Reco_Policy_Cat</th>\n",
       "      <th>Reco_Policy_Premium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50883</td>\n",
       "      <td>C1</td>\n",
       "      <td>156</td>\n",
       "      <td>Owned</td>\n",
       "      <td>Individual</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>11934.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50884</td>\n",
       "      <td>C4</td>\n",
       "      <td>7</td>\n",
       "      <td>Owned</td>\n",
       "      <td>Joint</td>\n",
       "      <td>69</td>\n",
       "      <td>68</td>\n",
       "      <td>Yes</td>\n",
       "      <td>X1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18</td>\n",
       "      <td>32204.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50885</td>\n",
       "      <td>C1</td>\n",
       "      <td>564</td>\n",
       "      <td>Rented</td>\n",
       "      <td>Individual</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>No</td>\n",
       "      <td>X3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17</td>\n",
       "      <td>9240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50886</td>\n",
       "      <td>C3</td>\n",
       "      <td>1177</td>\n",
       "      <td>Rented</td>\n",
       "      <td>Individual</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>No</td>\n",
       "      <td>X3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18</td>\n",
       "      <td>9086.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50887</td>\n",
       "      <td>C1</td>\n",
       "      <td>951</td>\n",
       "      <td>Owned</td>\n",
       "      <td>Individual</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>No</td>\n",
       "      <td>X3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>22534.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID City_Code  Region_Code Accomodation_Type Reco_Insurance_Type  \\\n",
       "0  50883        C1          156             Owned          Individual   \n",
       "1  50884        C4            7             Owned               Joint   \n",
       "2  50885        C1          564            Rented          Individual   \n",
       "3  50886        C3         1177            Rented          Individual   \n",
       "4  50887        C1          951             Owned          Individual   \n",
       "\n",
       "   Upper_Age  Lower_Age Is_Spouse Health Indicator Holding_Policy_Duration  \\\n",
       "0         30         30        No              NaN                     6.0   \n",
       "1         69         68       Yes               X1                     3.0   \n",
       "2         28         28        No               X3                     2.0   \n",
       "3         23         23        No               X3                     3.0   \n",
       "4         75         75        No               X3                     NaN   \n",
       "\n",
       "   Holding_Policy_Type  Reco_Policy_Cat  Reco_Policy_Premium  \n",
       "0                  3.0                5              11934.0  \n",
       "1                  3.0               18              32204.8  \n",
       "2                  4.0               17               9240.0  \n",
       "3                  3.0               18               9086.0  \n",
       "4                  NaN                5              22534.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50882, 14), (21805, 13))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __We have 50882 rows and 14 columns in Train set whereas Test set has 21805 rows and 13 columns.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                             0\n",
       "City_Code                      0\n",
       "Region_Code                    0\n",
       "Accomodation_Type              0\n",
       "Reco_Insurance_Type            0\n",
       "Upper_Age                      0\n",
       "Lower_Age                      0\n",
       "Is_Spouse                      0\n",
       "Health Indicator           11691\n",
       "Holding_Policy_Duration    20251\n",
       "Holding_Policy_Type        20251\n",
       "Reco_Policy_Cat                0\n",
       "Reco_Policy_Premium            0\n",
       "Response                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sum of null values in train data\n",
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                            0\n",
       "City_Code                     0\n",
       "Region_Code                   0\n",
       "Accomodation_Type             0\n",
       "Reco_Insurance_Type           0\n",
       "Upper_Age                     0\n",
       "Lower_Age                     0\n",
       "Is_Spouse                     0\n",
       "Health Indicator           5027\n",
       "Holding_Policy_Duration    8603\n",
       "Holding_Policy_Type        8603\n",
       "Reco_Policy_Cat               0\n",
       "Reco_Policy_Premium           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sum of null values in test data\n",
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Data of train data --> 6 \n",
      " ['City_Code', 'Accomodation_Type', 'Reco_Insurance_Type', 'Is_Spouse', 'Health Indicator', 'Holding_Policy_Duration']\n",
      "*****************************************************************************\n",
      "Numerical Data of train data --> 6\n"
     ]
    }
   ],
   "source": [
    "# Categorical Data\n",
    "train_categorical = train_df.select_dtypes(include=[np.object])\n",
    "obj_col = [col for col in train_df.keys() if train_df[col].dtype=='O']\n",
    "print('Categorical Data of train data -->', train_categorical.shape[1],'\\n',  obj_col)\n",
    "print('*****************************************************************************')\n",
    "\n",
    "# Numerical Data\n",
    "train_numerical = train_df.select_dtypes(include=[np.int64])\n",
    "print('Numerical Data of train data -->', train_numerical.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Data of test data --> 6 \n",
      " ['City_Code', 'Accomodation_Type', 'Reco_Insurance_Type', 'Is_Spouse', 'Health Indicator', 'Holding_Policy_Duration']\n",
      "*****************************************************************************\n",
      "Numerical Data of test data --> 5\n"
     ]
    }
   ],
   "source": [
    "# Categorical Data\n",
    "test_categorical = test_df.select_dtypes(include=[np.object])\n",
    "obj_col_test = [col for col in test_df.keys() if test_df[col].dtype=='O']\n",
    "print('Categorical Data of test data -->', test_categorical.shape[1],'\\n',  obj_col_test)\n",
    "print('*****************************************************************************')\n",
    "\n",
    "# Numerical Data\n",
    "test_numerical = test_df.select_dtypes(include=[np.int64])\n",
    "print('Numerical Data of test data -->', test_numerical.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Cleaning required in these column**\n",
    "- __Health Indicator        --->  __11691__\n",
    "- __Holding_Policy_Duration --->  __20251__\n",
    "- __Holding_Policy_Type     --->  __20251__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __5.1 Lets start with Health Indicator column.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['X1', 'X2', nan, 'X4', 'X3', 'X6', 'X5', 'X8', 'X7', 'X9'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Health Indicator'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imp(col):\n",
    "    train_df['Health Indicator']\n",
    "  \n",
    "    if col=='X1':\n",
    "        return 1\n",
    "    elif col=='X2':\n",
    "        return 2\n",
    "    elif col=='X3':\n",
    "        return 3\n",
    "    elif col=='X4':\n",
    "        return 4\n",
    "    elif col=='X5':\n",
    "        return 5\n",
    "    elif col=='X6':\n",
    "        return 6\n",
    "    elif col=='X7':\n",
    "        return 7\n",
    "    elif col=='X8':\n",
    "        return 8\n",
    "    elif col=='X9':\n",
    "        return 9\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train Data \n",
    "train_df['Health Indicator'] = train_df['Health Indicator'].apply(imp).astype(float)\n",
    "train_df['Health Indicator'] = train_df['Health Indicator'].replace('nan',np.nan)\n",
    "# Test Data\n",
    "test_df['Health Indicator'] = test_df['Health Indicator'].apply(imp).astype(float)\n",
    "test_df['Health Indicator'] = test_df['Health Indicator'].replace('nan',np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __5.2 Holding_Policy_Duration column.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['14+', nan, '1.0', '3.0', '5.0', '9.0', '14.0', '7.0', '2.0',\n",
       "       '11.0', '10.0', '8.0', '6.0', '4.0', '13.0', '12.0'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Holding_Policy_Duration'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['6.0', '3.0', '2.0', nan, '14+', '5.0', '1.0', '4.0', '12.0',\n",
       "       '11.0', '7.0', '9.0', '13.0', '8.0', '14.0', '10.0'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['Holding_Policy_Duration'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Holding_Policy_Duration'] = train_df['Holding_Policy_Duration'].replace('14+','14')\n",
    "\n",
    "test_df['Holding_Policy_Duration'] = test_df['Holding_Policy_Duration'].replace('14+','14')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __5.3 Holding_Policy_Type column.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3., nan,  1.,  4.,  2.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Holding_Policy_Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.,  4., nan,  1.,  2.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['Holding_Policy_Type'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __5.5 Label Encoder.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intiallising Encoder\n",
    "encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['City_Code'] = encoder.fit_transform(train_df['City_Code'])\n",
    "test_df['City_Code'] = encoder.fit_transform(test_df['City_Code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Accomodation_Type'] = pd.get_dummies(train_df['Accomodation_Type'],drop_first=False)\n",
    "train_df['Reco_Insurance_Type'] = pd.get_dummies(train_df['Reco_Insurance_Type'],drop_first=False)\n",
    "train_df['Is_Spouse'] = pd.get_dummies(train_df['Is_Spouse'],drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Accomodation_Type'] = pd.get_dummies(test_df['Accomodation_Type'],drop_first=False)\n",
    "test_df['Reco_Insurance_Type'] = pd.get_dummies(test_df['Reco_Insurance_Type'],drop_first=False)\n",
    "test_df['Is_Spouse'] = pd.get_dummies(test_df['Is_Spouse'],drop_first=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __5.6 Missing Value Treatment.__\n",
    "__KNN Imputer .__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnimputer = KNNImputer(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_tr = train_df.keys()\n",
    "key_ts = test_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = knnimputer.fit_transform(train_df)\n",
    "test_df = knnimputer.fit_transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.DataFrame(train_df,columns=key_tr)\n",
    "test_df=pd.DataFrame(test_df,columns=key_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1. , 2. , 3.2, 2.8, 4. , 3. , 2.6, 6. , 5. , 1.4, 1.8, 3.4, 2.2,\n",
       "       4.8, 1.6, 2.4, 3.6, 1.2, 3.8, 8. , 7. , 4.2, 4.6, 4.4, 9. , 5.2,\n",
       "       5.8])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Health Indicator'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Health Indicator'] = np.ceil(train_df['Health Indicator'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Now, we are done with Missing Value.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split DEPENDENT AND INDEPENDENT variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=train_df.drop(['Response', 'ID', 'City_Code', 'Region_Code'],axis=1)\n",
    "y=train_df['Response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50882, 10)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50882"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accomodation_Type</th>\n",
       "      <th>Reco_Insurance_Type</th>\n",
       "      <th>Upper_Age</th>\n",
       "      <th>Lower_Age</th>\n",
       "      <th>Is_Spouse</th>\n",
       "      <th>Health Indicator</th>\n",
       "      <th>Holding_Policy_Duration</th>\n",
       "      <th>Holding_Policy_Type</th>\n",
       "      <th>Reco_Policy_Cat</th>\n",
       "      <th>Reco_Policy_Premium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>11628.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accomodation_Type  Reco_Insurance_Type  Upper_Age  Lower_Age  Is_Spouse  \\\n",
       "0                0.0                  1.0       36.0       36.0        1.0   \n",
       "\n",
       "   Health Indicator  Holding_Policy_Duration  Holding_Policy_Type  \\\n",
       "0               1.0                     14.0                  3.0   \n",
       "\n",
       "   Reco_Policy_Cat  Reco_Policy_Premium  \n",
       "0             22.0              11628.0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaler.fit_transform(X)\n",
    "test_df = scaler.fit_transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50882, 10)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50882,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_key = key_tr.drop(['ID', 'City_Code', 'Region_Code', 'Response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pd.DataFrame(X,columns=X_key)\n",
    "test_df=pd.DataFrame(test_df,columns=key_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state =101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in c:\\users\\utkar\\anaconda3\\lib\\site-packages (0.0)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from imblearn) (0.7.0)\n",
      "Requirement already satisfied: scikit-learn>=0.23 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (0.23.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.18.5)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.5.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (0.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from scikit-learn>=0.23->imbalanced-learn->imblearn) (2.1.0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_smote, y_train_smote = smote.fit_sample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyper Parameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\n",
    " \"learning_rate\"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,\n",
    " \"max_depth\"        : [ 3, 4, 5, 6, 8, 10, 12, 15],\n",
    " \"min_child_weight\" : [ 1, 3, 5, 7 ],\n",
    " \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    " \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_model = XGBClassifier(max_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search=RandomizedSearchCV(xgboost_model,param_distributions=params,n_iter=5,scoring='roc_auc',n_jobs=-1,cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:18:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, gamma=None,\n",
       "                                           gpu_id=None, importance_type='gain',\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None,\n",
       "                                           max_delta_step=None, max_depth=10,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           n_estimators=100, n_...\n",
       "                                           random_state=None, reg_alpha=None,\n",
       "                                           reg_lambda=None,\n",
       "                                           scale_pos_weight=None,\n",
       "                                           subsample=None, tree_method=None,\n",
       "                                           validate_parameters=None,\n",
       "                                           verbosity=None),\n",
       "                   n_iter=5, n_jobs=-1,\n",
       "                   param_distributions={'colsample_bytree': [0.3, 0.4, 0.5,\n",
       "                                                             0.7],\n",
       "                                        'gamma': [0.0, 0.1, 0.2, 0.3, 0.4],\n",
       "                                        'learning_rate': [0.05, 0.1, 0.15, 0.2,\n",
       "                                                          0.25, 0.3],\n",
       "                                        'max_depth': [3, 4, 5, 6, 8, 10, 12,\n",
       "                                                      15],\n",
       "                                        'min_child_weight': [1, 3, 5, 7]},\n",
       "                   scoring='roc_auc')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_child_weight': 1,\n",
       " 'max_depth': 8,\n",
       " 'learning_rate': 0.05,\n",
       " 'gamma': 0.4,\n",
       " 'colsample_bytree': 0.4}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbclassifier = XGBClassifier(base_score=None, booster=None,\n",
    "                                           colsample_bylevel=None,\n",
    "                                           colsample_bynode=None,\n",
    "                                           colsample_bytree=None, gamma=None,\n",
    "                                           gpu_id=None, importance_type='gain',\n",
    "                                           interaction_constraints=None,\n",
    "                                           learning_rate=None,\n",
    "                                           max_delta_step=None, max_depth=10,\n",
    "                                           min_child_weight=None,\n",
    "                                           monotone_constraints=None,\n",
    "                                           n_estimators=100,\n",
    "                                           random_state=None, reg_alpha=None,\n",
    "                                           reg_lambda=None,\n",
    "                                           scale_pos_weight=None,\n",
    "                                           subsample=None, tree_method=None,\n",
    "                                           validate_parameters=None,\n",
    "                                           verbosity=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:18:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=10,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbclassifier.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:19:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=10,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbclassifier.fit(X_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = xgbclassifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_smote = xgbclassifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5541105048002314"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_score = roc_auc_score(pred_smote, y_test)\n",
    "roc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7348837209302326"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = accuracy_score(pred_smote, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictionht = xgbclassifier.predict(test_df.drop(['ID', 'City_Code', 'Region_Code'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21805,)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_predictionht.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(final_predictionht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0.])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    21017\n",
       "0.0      788\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission_QrCyCoT.csv')\n",
    "final_predictions = xgbclassifier.predict(test_df.drop(['ID', 'City_Code', 'Region_Code'],axis=1))\n",
    "submission['Response'] = final_predictionht\n",
    "#only positive predictions for the target variable\n",
    "\n",
    "submission.to_csv('XGBOOST3smote_ht.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
